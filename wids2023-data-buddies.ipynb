{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom catboost import CatBoostRegressor\nfrom statsmodels.tsa.arima.model import ARIMA\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom scipy.stats import uniform, randint\nfrom sklearn.pipeline import Pipeline\nfrom skopt import BayesSearchCV\nfrom skopt.space import Real, Integer\nimport gc\nimport lightgbm as lgb\nimport optuna\n%matplotlib inline\nprint(\"Libraries imported\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-16T00:56:32.921963Z","iopub.execute_input":"2023-02-16T00:56:32.922365Z","iopub.status.idle":"2023-02-16T00:56:36.142723Z","shell.execute_reply.started":"2023-02-16T00:56:32.922333Z","shell.execute_reply":"2023-02-16T00:56:36.141731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ^ These imports are becoming messy :^(","metadata":{}},{"cell_type":"markdown","source":"# Loading the data into variables cc_train, cc_test, cc_sample\n\n- cc_train = /kaggle/input/widsdatathon2023/train_data.csv\n- cc_test = /kaggle/input/widsdatathon2023/test_data.csv\n- cc_sample = /kaggle/input/widsdatathon2023/sample_solution.csv","metadata":{}},{"cell_type":"code","source":"cc_train = pd.read_csv('/kaggle/input/widsdatathon2023/train_data.csv')\ncc_test = pd.read_csv('/kaggle/input/widsdatathon2023/test_data.csv')\ncc_sample = pd.read_csv('/kaggle/input/widsdatathon2023/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:56:52.95148Z","iopub.execute_input":"2023-02-16T00:56:52.951895Z","iopub.status.idle":"2023-02-16T00:57:15.86449Z","shell.execute_reply.started":"2023-02-16T00:56:52.951852Z","shell.execute_reply":"2023-02-16T00:57:15.863377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reducing the memory usage of the dataset\n\n## Acknowledgement\n\n[Reduce Dataframe size](https://www.kaggle.com/competitions/widsdatathon2023/discussion/376649)","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(dataframe, verbose=True):\n  numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n  start_memory = dataframe.memory_usage().sum() / 1024**2\n  for col in dataframe.columns:\n    col_type = dataframe[col].dtypes\n    if col_type in numerics:\n      c_min = dataframe[col].min()\n      c_max = dataframe[col].max()\n      if str(col_type)[:3] == 'int':\n        if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n          dataframe[col] = dataframe[col].astype(np.int8)\n        elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n          dataframe[col] = dataframe[col].astype(np.int16)\n        elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n          dataframe[col] = dataframe[col].astype(np.int32)\n        elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n          dataframe[col] = dataframe[col].astype(np.int64)\n      else:\n        if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n          dataframe[col] = dataframe[col].astype(np.float32)\n        else:\n          dataframe[col] = dataframe[col].astype(np.float64)\n  end_memory = dataframe.memory_usage().sum() / 1024**2\n  print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_memory, 100 * (start_memory - end_memory) / start_memory)) if verbose else print('Reduced to {:5.2f}'.format(end_memory))\n  return dataframe","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:57:28.414049Z","iopub.execute_input":"2023-02-16T00:57:28.414508Z","iopub.status.idle":"2023-02-16T00:57:28.435419Z","shell.execute_reply.started":"2023-02-16T00:57:28.414453Z","shell.execute_reply":"2023-02-16T00:57:28.433817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_train = reduce_mem_usage(cc_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:57:31.697284Z","iopub.execute_input":"2023-02-16T00:57:31.698262Z","iopub.status.idle":"2023-02-16T00:58:00.289574Z","shell.execute_reply.started":"2023-02-16T00:57:31.698212Z","shell.execute_reply":"2023-02-16T00:58:00.288278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overview of the dataset\n\nUsing shape, info, head, describe","metadata":{}},{"cell_type":"code","source":"train_df = cc_train.copy()\ntest_df = cc_test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:58:05.633193Z","iopub.execute_input":"2023-02-16T00:58:05.633572Z","iopub.status.idle":"2023-02-16T00:58:06.008622Z","shell.execute_reply.started":"2023-02-16T00:58:05.63354Z","shell.execute_reply":"2023-02-16T00:58:06.007496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tukey's Method to detect outliers\n\n---\n\nTukey's method is used for identifying and removing outliers from a dataset. It involves using the interquartile range (IQR), which is the range between the 25th and 75th percentiles of the data, to determine whether a data point is an outlier. Any data points that fall outside of the range (Q1 - 1.5IQR, Q3 + 1.5IQR) are considered outliers and can be removed. This method is a simple and effective way to handle outliers in a dataset.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import iqr\n\ndef remove_outliers_tukey(data, alpha=1.5):\n    '''\n    Remove outliers using Tukey's method with the interquartile range (IQR).\n    \n    Parameters:\n    data (numpy array or pandas dataframe): The data to remove outliers from.\n    alpha (float): The sensitivity parameter, which determines the range to consider outliers.\n                   A value of 1.5 is the default, which is a commonly used value.\n    \n    Returns:\n    numpy array or pandas dataframe: The data with outliers removed.\n    '''\n    # Select only the numerical columns\n    num_cols = data.select_dtypes(include=[np.number]).columns\n    data_num = data[num_cols]\n    \n    # Compute the first and third quartiles\n    q1, q3 = np.percentile(data_num, [25, 75])\n    \n    # Compute the interquartile range (IQR)\n    iqr_val = iqr(data_num)\n    \n    # Compute the range outside of which data points are considered outliers\n    outlier_range = (q1 - alpha * iqr_val, q3 + alpha * iqr_val)\n    \n    # Identify the outliers and remove them\n    outliers = (data_num < outlier_range[0]) | (data_num > outlier_range[1])\n    data_num_no_outliers = data_num[~outliers]\n    \n    # Merge the numerical columns back into the original data frame\n    data_no_outliers = pd.concat([data_num_no_outliers, data.select_dtypes(exclude=[np.number])], axis=1)\n    \n    return data_no_outliers\n\ndata_with_removed_outliers = remove_outliers_tukey(train_df)\ndata_with_removed_outliers.shape\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_with_removed_outliers.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_with_removed_outliers.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the time gap between the train and the test data","metadata":{}},{"cell_type":"code","source":"# create a scatterplot using seaborn and matplotlib\nfig, ax = plt.subplots(figsize=(16, 8))\nsb.scatterplot(x=train_df.startdate, y=1, color='blue', label='Train Data', ax=ax)\nsb.scatterplot(x=test_df.startdate, y=1, color='red', label='Test Data', ax=ax)\n\n# add labels and a title to the plot\nax.set_title('Scatterplot of Startdate and Target')\nax.set_xlabel('Startdate')\nax.set_ylabel('Target')\nax.legend(loc='upper left')\n\n# display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T21:41:33.376855Z","iopub.execute_input":"2023-02-15T21:41:33.377339Z","iopub.status.idle":"2023-02-15T21:41:42.160564Z","shell.execute_reply.started":"2023-02-15T21:41:33.377303Z","shell.execute_reply":"2023-02-15T21:41:42.159313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Based on the graph above the train data was from 2014 - 2016 and the test data is from 2022. There is a big time gap between the train and test data.**","metadata":{}},{"cell_type":"markdown","source":"## Analyising the distribution of values in both the train and test dataset","metadata":{}},{"cell_type":"code","source":"def dist_of_train_test_features(train_df, test_df, feature):\n    # Analyse the distribution of values in the training dataset\n    plt.figure(figsize=(16, 5))\n    sb.displot(data=train_df, x=feature, kind='kde', label='Train Data')\n\n    # Analyse the distribution of values in the testing dataset\n    plt.figure(figsize=(16, 5))\n    sb.displot(data=test_df, x=feature, kind='kde', label='Test Data')\n# dist_of_train_test_features(train_df, test_df, 'nmme0-tmp2m-34w__nmme0mean')","metadata":{"execution":{"iopub.status.busy":"2023-02-14T03:08:57.964085Z","iopub.execute_input":"2023-02-14T03:08:57.964464Z","iopub.status.idle":"2023-02-14T03:09:00.41534Z","shell.execute_reply.started":"2023-02-14T03:08:57.964432Z","shell.execute_reply":"2023-02-14T03:09:00.413241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-14T02:29:05.062102Z","iopub.execute_input":"2023-02-14T02:29:05.062558Z","iopub.status.idle":"2023-02-14T02:29:05.070889Z","shell.execute_reply.started":"2023-02-14T02:29:05.06252Z","shell.execute_reply":"2023-02-14T02:29:05.069714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T02:29:08.583466Z","iopub.execute_input":"2023-02-14T02:29:08.583871Z","iopub.status.idle":"2023-02-14T02:29:11.932983Z","shell.execute_reply.started":"2023-02-14T02:29:08.583834Z","shell.execute_reply":"2023-02-14T02:29:11.931844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-14T03:08:27.166257Z","iopub.execute_input":"2023-02-14T03:08:27.166696Z","iopub.status.idle":"2023-02-14T03:08:27.174252Z","shell.execute_reply.started":"2023-02-14T03:08:27.166661Z","shell.execute_reply":"2023-02-14T03:08:27.173075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_sample.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T02:29:49.804554Z","iopub.execute_input":"2023-02-14T02:29:49.804946Z","iopub.status.idle":"2023-02-14T02:29:49.82738Z","shell.execute_reply.started":"2023-02-14T02:29:49.804914Z","shell.execute_reply":"2023-02-14T02:29:49.826356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the target variable\n`contest-tmp2m-14d__tmp2m`","metadata":{}},{"cell_type":"code","source":"def target_var_visualized():\n  plt.figure(figsize=(15,7))\n  plt.subplot(121)\n  sb.kdeplot(cc_train['contest-tmp2m-14d__tmp2m'], color = \"#ffd514\")\n  plt.subplot(122)\n  sb.boxplot(data=cc_train['contest-tmp2m-14d__tmp2m'], color = \"#ff355d\")\ntarget_var_visualized()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Displaying the distribution of the target variable in the train and test","metadata":{}},{"cell_type":"code","source":"def histogram_plot(data, label, title):\n    sb.histplot(data, color='blue', label=label)\n    plt.legend()\n    plt.title(title)\n    plt.show()\nhistogram_plot(data=cc_train['contest-tmp2m-14d__tmp2m'], label=\"contest-tmp2m-14d__tmp2m\", title=\"Target Variable distribution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The target variable is not in the test dataset**","metadata":{}},{"cell_type":"markdown","source":"### Simple for loop to list out the features from the train dataset","metadata":{}},{"cell_type":"code","source":"'''\ntest_col = cc_test.columns\ncount = 0\nfor name in test_col:\n  if count % 50 == 0:\n    print()\n  print(name + ', ', end='')\n  count += 1\n'''","metadata":{"_kg_hide-input":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_train.columns[cc_train.isna().any()].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_test.columns[cc_test.isna().any()].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_sample.columns[cc_sample.isna().any()].tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_dist(train, test):\n    fig, ax = plt.subplots(figsize = (10, 5))\n    sb.kdeplot(data=train,  color='blue', fill=True, ax=ax, label=\"Train Data\")\n    sb.kdeplot(data=test, color='orange', fill=True, ax=ax, label=\"Test Data\")\n    plt.legend()\n    plt.show()\n    \n#train_target = cc_train['contest-tmp2m-14d__tmp2m']\n#test_target = cc_test['contest-tmp2m-14d__tmp2m']\ntrain_target = cc_train['nmme0-tmp2m-34w__nmme0mean']\ntest_target = cc_test['nmme0-tmp2m-34w__nmme0mean']\ntrain_test_dist(train_target, test_target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualising Categorical columns","metadata":{}},{"cell_type":"code","source":"\n# Plot bar plots for all categorical columns\nfor column in cc_train.select_dtypes(include=['object']).columns:\n    cc_train[column].value_counts().plot(kind='bar', figsize=(10,5))\n    plt.title(column)\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef plot_boxplots(data, target_column):\n    num_cols = data.select_dtypes(exclude=['object']).columns\n    for col in num_cols:\n        plt.figure(figsize=(10, 5))\n        sb.boxplot(x=target_column, y=col, data=data)\n        plt.title(col + \" vs \" + target_column)\n        plt.show()\nplot_boxplots(cc_train, 'contest-tmp2m-14d__tmp2m')\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualising Numerical Columns","metadata":{}},{"cell_type":"code","source":"# Plot histograms for all numerical columns\nnum_cols = cc_train.columns\ndef plot_histograms(data, column_list):\n    \"\"\"\n    This function plots histograms based on the number of columns and data provided.\n    \n    Parameters\n    ----------\n    data : pandas dataframe\n        The data to be plotted.\n    column_list : a list\n        The list of 10 numerical column names from the dataset..\n    \n    Returns\n    -------\n    void\n        Displays histograms from matplotlib.\n        The histograms that are being plotted are frequency histograms \n        for the numerical columns specified in the column_list parameter .\n    \"\"\"\n    num_cols = column_list\n    for col in num_cols:\n        plt.figure(figsize=(8, 6))\n        data[col].hist(bins=50)\n        plt.title(col)\n        plt.tight_layout()\n        plt.show()\n        \n# plot_histograms(cc_train, num_cols[:10])","metadata":{"execution":{"iopub.status.busy":"2023-02-12T01:43:18.694723Z","iopub.execute_input":"2023-02-12T01:43:18.695011Z","iopub.status.idle":"2023-02-12T01:44:56.437635Z","shell.execute_reply.started":"2023-02-12T01:43:18.694984Z","shell.execute_reply":"2023-02-12T01:44:56.436355Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Null Imputation","metadata":{}},{"cell_type":"code","source":"#cc_train['nmme0-prate-34w__ccsm30'] = cc_train['nmme0-prate-34w__ccsm30'].fillna(cc_train['nmme0-prate-34w__ccsm30'].mean())\n#cc_train['nmme0-tmp2m-34w__ccsm30'] = cc_train['nmme0-tmp2m-34w__ccsm30'].fillna(cc_train['nmme0-tmp2m-34w__ccsm30'].mean())\n#cc_train['ccsm30'] = cc_train['ccsm30'].fillna(cc_train['ccsm30'].mean())\n#cc_train['nmme0-prate-56w__ccsm30'] = cc_train['nmme0-prate-56w__ccsm30'].fillna(cc_train['nmme0-prate-56w__ccsm30'].mean())\n#cc_train['nmme-tmp2m-56w__ccsm3'] = cc_train['nmme-tmp2m-56w__ccsm3'].fillna(cc_train['nmme-tmp2m-56w__ccsm3'].mean())\n#cc_train['nmme-prate-56w__ccsm3'] = cc_train['nmme-prate-56w__ccsm3'].fillna(cc_train['nmme-prate-56w__ccsm3'].mean())\n#cc_train['nmme-tmp2m-34w__ccsm3'] = cc_train['nmme-tmp2m-34w__ccsm3'].fillna(cc_train['nmme-tmp2m-34w__ccsm3'].mean())\n#cc_train['nmme-prate-34w__ccsm3'] = cc_train['nmme-prate-34w__ccsm3'].fillna(cc_train['nmme-prate-34w__ccsm3'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"#cc_train['year']=pd.DatetimeIndex(cc_train['startdate']).year \n#cc_train['month']=pd.DatetimeIndex(cc_train['startdate']).month \n#cc_train['day']=pd.DatetimeIndex(cc_train['startdate']).day\n#cc_test['year']=pd.DatetimeIndex(cc_test['startdate']).year \n#cc_test['month']=pd.DatetimeIndex(cc_test['startdate']).month \n#cc_test['day']=pd.DatetimeIndex(cc_test['startdate']).day","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preproccessing","metadata":{}},{"cell_type":"code","source":"def location_feature(train, test):\n    # Reference: https://www.kaggle.com/code/flaviafelicioni/wids-2023-different-locations-train-test-solved\n    scale = 14\n    train.loc[:,'lat']=round(train.lat,scale)\n    train.loc[:,'lon']=round(train.lon,scale)\n    test.loc[:,'lat']=round(test.lat,scale)\n    test.loc[:,'lon']=round(test.lon,scale)\n    \n    train_and_test = pd.concat([train, test], axis=0)\n    train_and_test['loc_group'] = train_and_test.groupby(['lat', 'lon']).ngroup()\n    print(f'{train_and_test.loc_group.nunique()} unique locations')\n    \n    train = train_and_test.iloc[:len(train)]\n    test = train_and_test.iloc[len(train):].drop(target, axis=1)\n    \n    return train, test\n\ndef cat_encode(train, test):\n    # encoding the categorical feature in the train and test data set\n    # using OneHotEncoder\n    ohe = OneHotEncoder()\n    train_encoded = ohe.fit_transform(train[['climateregions__climateregion']])\n    test_encoded = ohe.transform(test[['climateregions__climateregion']])\n    \n    train = train.drop(['climateregions__climateregion'], axis=1)\n    test = test.drop(['climateregions__climateregion'], axis=1)\n    \n    train_encoded = pd.DataFrame(train_encoded.toarray(), columns=ohe.get_feature_names_out(['climateregions__climateregion']))\n    test_encoded = pd.DataFrame(test_encoded.toarray(), columns=ohe.get_feature_names_out(['climateregions__climateregion']))\n    \n    train = pd.concat([train, train_encoded], axis=1)\n    test = pd.concat([test, test_encoded], axis=1)\n    \n    return train, test\n\n    \ndef fill_na_rows(dataset):\n    # Find the columns with missing values\n    columns_with_missing_values = dataset.columns[dataset.isnull().any()].tolist()\n    \n    # Impute the missing values with the mean value of that column\n    for col in columns_with_missing_values:\n        dataset[col].fillna(dataset[col].mean(), inplace=True)\n        \n    return dataset\n\ndef create_new_feat(dataset):\n    dataset['year']=pd.DatetimeIndex(dataset['startdate']).year \n    dataset['month']=pd.DatetimeIndex(dataset['startdate']).month \n    dataset['day']=pd.DatetimeIndex(dataset['startdate']).day\n    return dataset\n\ndef feature_engineering(origin_train, origin_test):\n    train, test = origin_train, origin_test\n    train = fill_na_rows(train)\n    train = create_new_feat(train)\n    test = create_new_feat(test)\n    train, test = cat_encode(train, test)\n    irrelevant_cols = ['index', 'startdate','contest-tmp2m-14d__tmp2m', 'climateregions__climateregion']\n    features = [col for col in train.columns if col not in irrelevant_cols]\n    #features = [col for col in train.columns]\n    X = train[features]\n    X_test = test[features]\n    y = train['contest-tmp2m-14d__tmp2m']\n    # Initialize the scaler\n    #scaler = MinMaxScaler()\n\n    # Fit the scaler to the train data\n    #scaler.fit(X)\n\n    # Transform the train data\n    #X_train_scaled = scaler.transform(X)\n\n    # Transform the test data\n    #X_test_scaled = scaler.transform(X_test)\n    \n    return X, y, X_test\n\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:58:24.960199Z","iopub.execute_input":"2023-02-16T00:58:24.96058Z","iopub.status.idle":"2023-02-16T00:58:24.977963Z","shell.execute_reply.started":"2023-02-16T00:58:24.96055Z","shell.execute_reply":"2023-02-16T00:58:24.976802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning Model\n## RandomForestRegressor\n\nRandom Forest Regressor is a commonly used machine learning algorithm for regression problems and was chosen in this case because:\n\n- It can handle both linear and non-linear relationships between features and target variables.\n\n- It can handle missing data and is robust to noisy data.\n\n- It is an ensemble method, which means it combines multiple decision trees to produce a more accurate and stable prediction.\n\n- It can provide feature importance scores, which can be useful in identifying the most important features in the data.\n\n- It is easy to implement and provides good results out-of-the-box, especially for large datasets with a large number of features.\n\nThese properties make Random Forest Regressor a good choice for a first attempt at solving this regression problem, and it can be a good starting point for further tuning and optimization","metadata":{}},{"cell_type":"markdown","source":"# Splittin the data set to train the model","metadata":{}},{"cell_type":"markdown","source":"Target variable: `contest-tmp2m-14d__tmp2m`\n\n[WiDS Datathon Challenge](https://www.kaggle.com/competitions/widsdatathon2023/data)\n\nDefinition of target variable: \n- the arithmetic mean of the max and min observed temperature over the next 14 days for each location and start date, is provided\n\nEvaluation Metric:\n\n[Evaluation Reference](https://www.kaggle.com/competitions/widsdatathon2023/overview/evaluation)\n\nRoot Mean Squared Error (RMSE)","metadata":{}},{"cell_type":"code","source":"target=\"contest-tmp2m-14d__tmp2m\"\ncc_test_copy = cc_test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:58:37.337803Z","iopub.execute_input":"2023-02-16T00:58:37.338536Z","iopub.status.idle":"2023-02-16T00:58:37.368027Z","shell.execute_reply.started":"2023-02-16T00:58:37.3385Z","shell.execute_reply":"2023-02-16T00:58:37.366806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and test sets\nX, y, X_test = feature_engineering(cc_train.copy(), cc_test.copy())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:58:47.610362Z","iopub.execute_input":"2023-02-16T00:58:47.611081Z","iopub.status.idle":"2023-02-16T01:00:10.232852Z","shell.execute_reply.started":"2023-02-16T00:58:47.611035Z","shell.execute_reply":"2023-02-16T01:00:10.23181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking Correlation","metadata":{}},{"cell_type":"code","source":"## Identify correlated features to drop that fall above a correlation threshold \n## https://goodboychan.github.io/python/datacamp/machine_learning/2020/07/08/02-Feature-selection-I-selecting-for-feature-information.html \n\ndef identify_correlated(df, threshold):\n    corr_matrix = df.corr().abs()\n    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n    reduced_corr_matrix = corr_matrix.mask(mask)\n    features_to_drop = [c for c in reduced_corr_matrix.columns if any(reduced_corr_matrix[c] > threshold)]\n    return features_to_drop","metadata":{"execution":{"iopub.status.busy":"2023-02-16T01:00:13.696333Z","iopub.execute_input":"2023-02-16T01:00:13.696682Z","iopub.status.idle":"2023-02-16T01:00:13.703627Z","shell.execute_reply.started":"2023-02-16T01:00:13.696652Z","shell.execute_reply":"2023-02-16T01:00:13.702408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# afterwards i should print out the columns that are of high importance from the models\n# perform PCA and see if it determines the same features as the corr_matrix\n# at.96 the score is ~1.24 (~51 columns dropped)\n# at .70 the score is ~1.4 (~100+ columns dropped)\n# at .80 the score is ~0.968 (100 columns dropped) - but why were these columns so unimportant that dropping it had a better outcome as compared to the other trials with .95 and .70 ?\n# **Besides the fact that they were highly correlated - at .70 had more columns but dropping the columns identifed at .70 had a worse score than .80\nfeatures_to_drop = identify_correlated(cc_train, .80)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T01:00:24.790183Z","iopub.execute_input":"2023-02-16T01:00:24.790539Z","iopub.status.idle":"2023-02-16T01:01:21.412341Z","shell.execute_reply.started":"2023-02-16T01:00:24.790508Z","shell.execute_reply":"2023-02-16T01:01:21.411193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(features_to_drop))\nprint(features_to_drop)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T22:22:47.165494Z","iopub.execute_input":"2023-02-15T22:22:47.165907Z","iopub.status.idle":"2023-02-15T22:22:47.173337Z","shell.execute_reply.started":"2023-02-15T22:22:47.165871Z","shell.execute_reply":"2023-02-15T22:22:47.171525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove_feature = ['index', 'contest-tmp2m-14d__tmp2m']\nfeatures_to_drop_v1 = [ele for ele in features_to_drop if ele not in remove_feature]\nfeatures_to_drop_v1","metadata":{"execution":{"iopub.status.busy":"2023-02-16T01:02:41.360972Z","iopub.execute_input":"2023-02-16T01:02:41.36135Z","iopub.status.idle":"2023-02-16T01:02:41.370281Z","shell.execute_reply.started":"2023-02-16T01:02:41.361317Z","shell.execute_reply":"2023-02-16T01:02:41.369239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc_train_reduced = pd.DataFrame(X.drop(features_to_drop_v1, axis=1))\ncc_test_reduced = pd.DataFrame(X_test.drop(features_to_drop_v1, axis=1))\nprint(\"Dropped features that are highly correlated\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T01:03:10.71516Z","iopub.execute_input":"2023-02-16T01:03:10.715529Z","iopub.status.idle":"2023-02-16T01:03:10.81328Z","shell.execute_reply.started":"2023-02-16T01:03:10.7155Z","shell.execute_reply":"2023-02-16T01:03:10.81199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def ensemble_predict(xgboost_preds, lightgbm_preds):\n    # combine the predictions of the two models\n    combined_preds = np.mean([xgboost_preds, lightgbm_preds], axis=0)\n    return combined_preds","metadata":{}},{"cell_type":"code","source":"X_train, X_test_tts, y_train, y_test = train_test_split(cc_train_reduced, y, test_size=0.33, random_state=42)\nprint(\"Split the dataset for training successfully\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T01:03:14.499559Z","iopub.execute_input":"2023-02-16T01:03:14.499931Z","iopub.status.idle":"2023-02-16T01:03:14.935568Z","shell.execute_reply.started":"2023-02-16T01:03:14.499898Z","shell.execute_reply":"2023-02-16T01:03:14.934314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using RandomForestRegressor","metadata":{}},{"cell_type":"markdown","source":"**Training and test performance**","metadata":{}},{"cell_type":"code","source":"'''\n# Train the Random Forest Regressor\nparams = {\n    'n_estimators': 5000,\n    'max_depth': 10,\n    'min_samples_split': 2,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'bootstrap': True,\n    'oob_score': True\n}\nregr_rfr = RandomForestRegressor(**params)\nregr_rfr.fit(X_train, y_train)\n# make predictions on the test data\ny_pred_rfr = regr_rfr.predict(X_test_tts)\n\n# calculate the RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_rfr))\nprint(\"RMSE:\", rmse)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cc_test_pred = regr_rfr.predict(cc_test_reduced)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cc_test_copy[target] = cc_test_pred\n# cc_test_copy[[target,\"index\"]].to_csv(\"rfrpredictions.csv\",index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using XGBoost\n\n*Gradient Boosted Decision Trees*\n\nXGBoost is short for Extreme Gradient Boosting. The implementation is designed for speed and performance. It is an efficient implementation of the stochastic gradient boosting algorithm.","metadata":{}},{"cell_type":"code","source":"# create a DMatrix from the training data\n#dtrain = xgb.DMatrix(data=X_train, label=y_train)\n#dtest = xgb.DMatrix(data=X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters used\nThese parameters are used to specify the hyperparameters for a gradient boosting tree (GBT) model in the XGBoost library.\n\n- **base_score**: It is the initial prediction score of all instances, global bias.\n\n- **booster**: It specifies which booster to use for model training. The value 'gbtree' indicates that a tree-based booster will be used.\n\n- **tree_method**: It specifies the method used to build the trees. The value 'gpu_hist' means that the histogram-based algorithm is used to build the trees on a GPU.\n\n- **n_estimators**: It is the number of trees in the forest. The higher the number, the more complex the model becomes, but also the longer it takes to train.\n\n- **early_stopping_rounds**: It is used to stop the training process early when the performance on a validation set starts to degrade. The value 50 indicates that training will be stopped if the performance on the validation set does not improve after 50 iterations.\n\n- **objective**: It defines the loss function to be minimized. The value 'reg:squarederror' means that the model will minimize the mean squared error between the predicted and actual values.\n\n- **max_depth**: It is the maximum depth of the trees in the model. The higher the value, the more complex the model becomes. Note: 2 - 8 is recommended, any higher value than 8 would not provide any more benefits.\n\n- **subsample**: It is the fraction of the training instances used to build each tree in the forest. The lower the value, the simpler the model becomes, but also the more prone to overfitting.\n\n- **colsample_bytree**: It is the fraction of the columns used to build each tree in the forest. The lower the value, the simpler the model becomes, but also the more prone to overfitting.\n\n- **learning_rate**: It is the step size at which the optimizer makes updates to the model weights. A lower value means that the model updates more slowly but with less noise.\n\n- **gpu_id**: It is the GPU device id to use for training. The value 0 indicates that the first GPU in the system will be used.","metadata":{}},{"cell_type":"markdown","source":"*Can use StratifiedKfold and gridsearhcv to determine the best combinations of parameters.*","metadata":{}},{"cell_type":"markdown","source":"> Note 1: I would like to reduce the value of the n_estimators will maintaining the same rmse or better.","metadata":{}},{"cell_type":"markdown","source":"> Note 2: Review the learning curve on the training and validation set","metadata":{}},{"cell_type":"code","source":"'''\n# set up parameters for XGBoost\n# list of learning_rates to test [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n# n_estimators = [50, 100, 150, 200]\n# max_depth = [2, 4, 6, 8]\n# param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\nprint(\"Training and predicting using xgboost\")\n# Define the search space for the hyperparameters\nparams = {'base_score': 0.5, \n          'booster': 'gbtree',\n          'tree_method': 'gpu_hist',\n          'n_estimators': 15000,\n          'objective': 'reg:squarederror',\n          'max_depth': 6,\n          'subsample': 0.5,\n          'colsample_bytree': 0.5,\n          'gamma': 1.4,\n          'min_child_weight': 7,\n          'learning_rate': 0.01,\n          'gpu_id': 0}\n\nreg_xgb = xgb.XGBRegressor(**params)\n\nreg_xgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test_tts, y_test)], verbose=1000)\n\n# get the feature importance scores\nimportance_scores = reg_xgb.feature_importances_\nfeature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': importance_scores})\nfeature_importances.to_csv(\"xgboostbestparameters.csv\")\n# sort the features by importance score\nfeature_importances = feature_importances.sort_values('importance', ascending=False)\nprint(feature_importances)\n\n\n# make predictions on the test data\ny_pred_xgb = reg_xgb.predict(X_test_tts)\n\n# calculate the RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\nprint(\"RMSE:\", rmse)\n\n\ncc_test_pred = reg_xgb.predict(cc_test_reduced)\ncc_test_copy[target] = cc_test_pred\ncc_test_copy[[target,\"index\"]].to_csv(\"xgbpredictions.csv\",index = False)\nprint(\"Finished training and fitting, created xgbpredictions,csv\")\n'''\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T01:00:39.143241Z","iopub.execute_input":"2023-02-13T01:00:39.144252Z","iopub.status.idle":"2023-02-13T01:00:39.220616Z","shell.execute_reply.started":"2023-02-13T01:00:39.144118Z","shell.execute_reply":"2023-02-13T01:00:39.219315Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef objective(trial):\n    params = {\n        'base_score': 0.5, \n        'booster': 'gbtree',\n        'tree_method': 'gpu_hist',\n        'n_estimators': 6000,\n        'objective': 'reg:squarederror',\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'subsample': trial.suggest_uniform('subsample', 0.1, 1.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1.0),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n        'verbosity': -1,\n        'gpu_id': 0\n    }\n\n    reg_xgb = xgb.XGBRegressor(**params)\n\n    reg_xgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test_tts, y_test)])\n\n    y_pred_xgb = reg_xgb.predict(X_test_tts)\n\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n\n    return rmse\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=15)\n\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:')\ntrial = study.best_trial\n\nprint(f'  Value: {trial.value:.5f}')\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print(f'    {key}: {value}')\n\nbest_params = trial.params\nreg_xgb = xgb.XGBRegressor(**best_params)\nreg_xgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test_tts, y_test)])\ny_pred_xgb = reg_xgb.predict(X_test_tts)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\nprint(\"RMSE:\", rmse)\n\ncc_test_pred = reg_xgb.predict(cc_test_reduced)\ncc_test_copy[target] = cc_test_pred\ncc_test_copy[[target,\"index\"]].to_csv(\"xgbpredictions.csv\",index = False)\nprint(\"Finished training and fitting, created xgbpredictions.csv\")\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How does catboost manage","metadata":{}},{"cell_type":"code","source":"'''\nfrom catboost import CatBoostRegressor\nparams = {'iterations': 15000,\n          'learning_rate': 0.01,\n          'depth': 6,\n          'l2_leaf_reg': 3,\n          'bagging_temperature': 1,\n          'border_count': 256,\n          'loss_function': 'RMSE',\n          'random_seed': None,\n          'task_type': 'GPU',\n          'verbose': 100}\n# Define the CatBoostRegressor object\nreg_catboost = CatBoostRegressor(**params)\n\n# Fit the model to the training data\nreg_catboost.fit(X_train, y_train, eval_set=(X_train, y_train))\n\n# Generate predictions on the test data\ny_pred_catboost = reg_catboost.predict(X_test_tts)\n\n# Calculate the RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_catboost))\nprint(\"RMSE:\", rmse)\n\n# Make predictions on the competition test data\ncc_test_copy_v2 = cc_test_copy.copy()\ncc_test_pred_catb = reg_catboost.predict(cc_test_reduced)\ncc_test_copy_v2[target] = cc_test_pred_catb\ncc_test_copy_v2[[target, \"index\"]].to_csv(\"catboost_predictions.csv\", index=False)\n'''\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using lasso and gradientboosting ensemble\n\nThis is taking too long. I need to find a way to speed up","metadata":{}},{"cell_type":"markdown","source":"# Using Lasso\n\nlasso = Lasso(alpha=0.005, random_state=1, max_iter=1000)\nlasso.fit(X_train, y_train)\ny_pred_lasso = lasso.predict(X_test_tts)\ncc_test_pred_lasso = lasso.predict(X_test)\ncc_test_copy[target] = cc_test_pred_lasso\ncc_test_copy[[target,\"index\"]].to_csv(\"lassopredictions.csv\",index = False)","metadata":{}},{"cell_type":"markdown","source":"# Using GradientBoostingRegressor\ngbr = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =5)\ngbr.fit(X_train, y_train)\ny_pred_gbr = gbr.predict(X_test_tts)\ncc_test_copy_v2 = cc_test_copy.copy()\ncc_test_pred_gbr = gbr.predict(X_test)\ncc_test_copy_v2[target] = cc_test_pred_gbr\ncc_test_copy_v2[[target, \"index\"]].to_csv(\"gbrpredictions.csv\", index = False)","metadata":{}},{"cell_type":"markdown","source":"# Using LightGBM\n\n## understanding hyperparameters\n\n[Amazon documentation on LightGBM](https://docs.aws.amazon.com/sagemaker/latest/dg/lightgbm-hyperparameters.html)","metadata":{}},{"cell_type":"code","source":"'''\nprint(\"Beginning training and fitting lightgbm model\")\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmse',\n    'num_leaves': 31,\n    'max_depth': 8,\n    'learning_rate': 0.03,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'min_child_samples': 50,\n    'min_data_in_leaf': 100,\n    'subsample_for_bin': 200000,\n    'n_estimators': 15000,\n    'early_stopping_rounds': 50,\n    'device_type': 'gpu'\n}\n\n# Create the LightGBM model object\nreg_lgb = lgb.LGBMRegressor(**params)\n\n# Fit the model to the training data\nreg_lgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test_tts, y_test)], verbose=1000)\n\n\n# Get feature importances\nimportance_scores = reg_lgb.feature_importances_\nfeature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': importance_scores})\n\n# Sort the features by importance score\nfeature_importances = feature_importances.sort_values('importance', ascending=False)\n\n# Output feature importances to a CSV file\nfeature_importances.to_csv(\"lgbm_feature_importances.csv\", index=False)\n\n# Generate predictions on the test data\ny_pred_lgb = reg_lgb.predict(X_test_tts)\n\n# Calculate the RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\nprint(\"RMSE:\", rmse)\n\n# Make predictions on the competition test data\ncc_test_copy_v2 = cc_test_copy.copy()\ncc_test_pred_lgb = reg_lgb.predict(cc_test_reduced)\ncc_test_copy_v2[target] = cc_test_pred_lgb\ncc_test_copy_v2[[target, \"index\"]].to_csv(\"lgbpredictions.csv\", index=False)\nprint(\"Finished training and fitting lightgbm model, created lgbpredictions.csv and feature_importances.csv\")\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n'''\n\ndef objective(trial):\n    params = {\n        'boosting_type': 'gbdt', \n        'objective': 'regression', \n        'metric': 'rmse', \n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n        'lambda_l1': trial.suggest_int('lambda_l1', 0, 100),\n        'lambda_l2': trial.suggest_int('lambda_l2', 0, 100),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'device_type':'gpu',\n        'verbosity': -1,\n        'n_estimators': 6000\n    }\n\n    reg_lgb = lgb.LGBMRegressor(**params)\n\n    reg_lgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test_tts, y_test)])\n\n    y_pred_lgb = reg_lgb.predict(X_test_tts)\n\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n\n    return rmse\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=15)\n\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:')\ntrial = study.best_trial\n\nprint(f'  Value: {trial.value:.5f}')\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print(f'    {key}: {value}')    \n\nbest_params = trial.params\nreg_lgb = lgb.LGBMRegressor(**best_params)\nreg_lgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test_tts, y_test)])\ny_pred_lgb = reg_lgb.predict(X_test_tts)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\nprint(\"RMSE:\", rmse)\n\ncc_test_copy_v2 = cc_test_copy.copy()\ncc_test_pred_lgb = reg_lgb.predict(cc_test_reduced)\ncc_test_copy_v2[target] = cc_test_pred_lgb\ncc_test_copy_v2[[target, \"index\"]].to_csv(\"lgbpredictions.csv\", index=False)\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cc_test_copy_v2 = cc_test_copy.copy()\ncc_test_pred_lgb = reg_lgb.predict(cc_test_reduced)\ncc_test_copy_v2[target] = cc_test_pred_lgb\ncc_test_copy_v2[[target,\"index\"]].to_csv(\"lgbpredictions.csv\",index = False)","metadata":{}},{"cell_type":"markdown","source":"## Let's try out using Robust Linear regression model from the statsmodel api\n\n---\n\nRobust regression models can be particularly useful for large datasets with many features, where outliers are common and can significantly impact the performance of the model. By using robust regression models, you can improve the reliability of your predictions and reduce the risk of overfitting to noisy or spurious data.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n\n# Fit a robust linear regression model\nrlm_model = sm.RLM(y_train, X_train, M=sm.robust.norms.Hampel())\nrlm_results = rlm_model.fit(scale_est=sm.robust.scale.HuberScale())\n\n# Print the summary of the model\nprint(rlm_results.summary())\n\n# Get the predicted values on the test set\ny_pred = rlm_results.predict(X_test_tts)\n\n# Calculate the RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"RMSE:\", rmse)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Multi-Layer Perceptron Models","metadata":{}},{"cell_type":"code","source":"'''\nparams = {'hidden_layer_sizes': (100,50,10), \n          'activation': 'relu',\n          'solver': 'adam',\n          'alpha': 0.0001,\n          'batch_size': 'auto',\n          'learning_rate': 'constant',\n          'learning_rate_init': 0.001,\n          'max_iter': 200,\n          'shuffle': True,\n          'random_state': None,\n          'tol': 0.0001,\n          'verbose': True,\n          'warm_start': False,\n          'momentum': 0.9,\n          'nesterovs_momentum': True,\n          'early_stopping': False,\n          'validation_fraction': 0.1,\n          'beta_1': 0.9,\n          'beta_2': 0.999,\n          'epsilon': 1e-08}\n\n# Standardize the data using a standard scaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test_tts = scaler.transform(X_test_tts)\n\nreg_mlp = MLPRegressor(**params)\n\nreg_mlp.fit(X_train, y_train)\n\n# make predictions on the test data\ny_pred_mlp = reg_mlp.predict(X_test_tts)\n\n# calculate the RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\nprint(\"RMSE:\", rmse)\n# Make predictions on the competition test data\ncc_test_copy_v2 = cc_test_copy.copy()\n\ncc_test_pred_mlp = reg_mlp.predict(cc_test_reduced)\ncc_test_copy_v2[target] = cc_test_pred_mlp\ncc_test_copy_v2[[target,\"index\"]].to_csv(\"mlppredictions.csv\",index = False)\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cc_test_copy_v2[target]","metadata":{}},{"cell_type":"markdown","source":"cc_test_copy[target]","metadata":{}},{"cell_type":"code","source":"#ensemble_preds = cc_test_copy_v2[target]*0.7+cc_test_copy[target]*0.3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ncc_submission = cc_test_copy.copy()\ncc_submission[target] = ensemble_preds\ncc_submission[[target,\"index\"]].to_csv('submission.csv', index = False)\n'''","metadata":{},"execution_count":null,"outputs":[]}]}